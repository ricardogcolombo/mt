{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de dígitos con KNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerías,\n",
    "de acuerdo al virtual env que estén corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install\n",
    "\n",
    "# Verifico la correcta instalación. Si no falla el import está OK\n",
    "!pwd\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import metnum as mt\n",
    "import datetime\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numpy import savetxt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#percentage over total of train cases\n",
    "PERCENTAGE_OF_TRAIN_CASES = 0.8\n",
    "#neighbors for finding the mode in KNN\n",
    "N_NEIGHBORS = 100\n",
    "#components for PCA\n",
    "N_COMPONENTS=40\n",
    "#number of iterations to find eigenvalues and eigenvectors in power iteration\n",
    "N_ITERATIONS=5000\n",
    "#epsilon for power iteration\n",
    "EPSILON=1e-10\n",
    "#directory for saving matrix files\n",
    "timestamp = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "DIRECTORY_NAME=\"{}\".format(timestamp)\n",
    "os.makedirs(DIRECTORY_NAME+\"/\", exist_ok=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "TOTAL_TRAIN_CASES = int(PERCENTAGE_OF_TRAIN_CASES*len(df_train))\n",
    "\n",
    "#shuffle the train cases.\n",
    "df_train = df_train[0: TOTAL_TRAIN_CASES].sample(frac=1)\n",
    "\n",
    "# Uso values para mandar todo a arrays de numpy\n",
    "X = df_train[df_train.columns[1:]].values\n",
    "y = df_train[\"label\"].values.reshape(-1, 1)\n",
    "\n",
    "limit = int(0.8 * X.shape[0]) \n",
    "\n",
    "X_train, y_train = X[:limit], y[:limit]\n",
    "X_val, y_val = X[limit:], y[limit:]\n",
    "\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_val) == len(y_val)\n",
    "\n",
    "print(f\"Ahora tengo {len(X_train)} instancias de entrenamiento y {len(X_val)} de validación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcional: guardamos las matrices de entrenamiento en un archivo si queremos reproducir el experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('{}/X_train.csv'.format(DIRECTORY_NAME), X_train, delimiter=',')\n",
    "savetxt('{}/y_train.csv'.format(DIRECTORY_NAME), y_train, delimiter=',')\n",
    "savetxt('{}/X_val.csv'.format(DIRECTORY_NAME), X_val, delimiter=',')\n",
    "savetxt('{}/y_val.csv'.format(DIRECTORY_NAME), y_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing sin PCA (raw data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el dato con los test cases sin modificar y probamos su accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = mt.KNNClassifier(N_NEIGHBORS)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val[0:])\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo para probar la capacidad del modelo a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_example= 598\n",
    "\n",
    "img = X_val[random_example].reshape(28, 28)\n",
    "plt.imshow(img, cmap=\"Greys\")\n",
    "\n",
    "print(\"Prediction: {} - Digit: {}\".format( int(y_pred[random_example]), int(y_val[random_example])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing con PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usamos PCA para transformar la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pca = mt.PCA(N_COMPONENTS, N_ITERATIONS, EPSILON)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca, X_val_pca = pca.transform(X_train), pca.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcional: guardamos las matrices de entrenamiento en un archivo si queremos reproducir el experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('{}/X_train_pca.csv'.format(DIRECTORY_NAME), X_train_pca, delimiter=',')\n",
    "savetxt('{}/X_val_pca.csv'.format(DIRECTORY_NAME), X_val_pca, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo con la data de PCA y testeamos accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = mt.KNNClassifier(N_NEIGHBORS)\n",
    "\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val_pca[0:])\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testeo automático moviendo parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import metnum as mt\n",
    "import datetime\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numpy import savetxt\n",
    "from sklearn.metrics import *\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def calculate_metrics(y_val, y_pred, time):\n",
    "    \n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average=None)\n",
    "    recall = recall_score(y_val, y_pred, average=None)\n",
    "    f1 = f1_score(y_val, y_pred, average=None)\n",
    "    kappa = -1#kappa_score(y_val, y_pred, average=None)\n",
    "    \n",
    "    return (acc, precision, recall, \n",
    "            f1, kappa, time)\n",
    "\n",
    "def pca_experiment_generic(variables):\n",
    "    \n",
    "    for variable in variables:\n",
    "        name = variable[\"name\"]\n",
    "        value = variable[\"value\"]\n",
    "        if(name==\"PERCENTAGE_OF_TRAIN_CASES\"):\n",
    "            PERCENTAGE_OF_TRAIN_CASES = value\n",
    "        elif (name==\"N_NEIGHBORS\"):\n",
    "            N_NEIGHBORS = value\n",
    "        elif (name==\"N_COMPONENTS\"):\n",
    "            N_COMPONENTS = value\n",
    "        elif (name == \"N_ITERATIONS\"):\n",
    "            N_ITERATIONS = value\n",
    "        elif(name == \"EPSILON\"):\n",
    "            EPSILON = value\n",
    "            \n",
    "    print(\"{} : {}\\n{} : {}\\n{} : {}\\n{} : {}\\n{} : {}\\n\".format(\"PERCENTAGE_OF_TRAIN_CASES\",PERCENTAGE_OF_TRAIN_CASES,\n",
    "                                                                 \"N_NEIGHBORS\",N_NEIGHBORS,\n",
    "                                                                 \"N_COMPONENTS\",N_COMPONENTS,\n",
    "                                                                 \"N_ITERATIONS\",N_ITERATIONS,\n",
    "                                                                 \"EPSILON\",EPSILON))\n",
    "    \n",
    "    return pca_experiment(PERCENTAGE_OF_TRAIN_CASES, \n",
    "                   N_NEIGHBORS, \n",
    "                   N_COMPONENTS, \n",
    "                   N_ITERATIONS, \n",
    "                   EPSILON)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "def pca_experiment(PERCENTAGE_OF_TRAIN_CASES, \n",
    "                   N_NEIGHBORS, \n",
    "                   N_COMPONENTS, \n",
    "                   N_ITERATIONS, \n",
    "                   EPSILON):\n",
    "    \n",
    "    start = time.time()\n",
    "    df_train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "    TOTAL_TRAIN_CASES = int(PERCENTAGE_OF_TRAIN_CASES*len(df_train))\n",
    "    #shuffle the train cases.\n",
    "    df_train = df_train[0: TOTAL_TRAIN_CASES].sample(frac=1)\n",
    "\n",
    "    # Uso values para mandar todo a arrays de numpy\n",
    "    X = df_train[df_train.columns[1:]].values\n",
    "    y = df_train[\"label\"].values.reshape(-1, 1)\n",
    "\n",
    "    limit = int(0.8 * X.shape[0]) \n",
    "\n",
    "    X_train, y_train = X[:limit], y[:limit]\n",
    "    X_val, y_val = X[limit:], y[limit:]\n",
    "    \n",
    "    pca = mt.PCA(N_COMPONENTS, N_ITERATIONS, EPSILON)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    X_train_pca, X_val_pca = pca.transform(X_train), pca.transform(X_val)\n",
    "    \n",
    "    clf = mt.KNNClassifier(N_NEIGHBORS)\n",
    "\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_val_pca[0:])\n",
    "    \n",
    "    return calculate_metrics(y_val, y_pred, time.time()-start)\n",
    "\n",
    "\n",
    "\n",
    "def create_df(variable, experiment_results):\n",
    "    df = pd.DataFrame(columns=[variable, 'ACCURACY', 'TIME'])\n",
    "    \n",
    "    for i in range(10):\n",
    "        df['PRECISION_'+str(i)] = np.NaN\n",
    "    for i in range(10):\n",
    "        df['RECALL_'+str(i)] = np.NaN\n",
    "    for i in range(10):\n",
    "        df['F1_'+str(i)] = np.NaN\n",
    "        \n",
    "    return df.append(experiment_results, sort=False)\n",
    "\n",
    "\n",
    "def experiment_generic_move_variable(variable_range, fixed_variables):\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%m-%d-%H-%M-%S\")\n",
    "    \n",
    "    experiment_results = []\n",
    "    \n",
    "    NAME_OF_VARIABLE = variable_range[\"name\"]\n",
    "    print(\"variable range: \"+str(variable_range)+\"\\nFixed variables:\"+str(fixed_variables))\n",
    "    \n",
    "    for value in variable_range[\"range\"]:\n",
    "        fixed_variables.append({\"name\":NAME_OF_VARIABLE, \"value\":value})\n",
    "        \n",
    "        (acc, precision, recall, \n",
    "         f1, kappa, execution_time) =  pca_experiment_generic(fixed_variables)\n",
    "        \n",
    "        data = {\n",
    "            NAME_OF_VARIABLE : value,\n",
    "            'ACCURACY' : acc,\n",
    "            'TIME' : round(execution_time)\n",
    "        }\n",
    "        \n",
    "        for i in range(10):\n",
    "            data['PRECISION_'+str(i)] = precision[i]\n",
    "            data['RECALL_'+str(i)] = recall[i]\n",
    "            data['F1_'+str(i)] = f1[i]\n",
    "            \n",
    "        experiment_results.append(data)\n",
    "        \n",
    "    filename='test_'+NAME_OF_VARIABLE+'-{}'.format(time.time())\n",
    "    \n",
    "    df_result = create_df(NAME_OF_VARIABLE, experiment_results)  \n",
    "    df_result.to_csv(filename+'.csv', encoding='utf-8', index=False)\n",
    "    \n",
    "    metadata = {\n",
    "        'TIMESTAMP' : [timestamp]\n",
    "    }\n",
    "    \n",
    "    metadata_columns = ['TIMESTAMP']\n",
    "    \n",
    "    for fixed_variable in fixed_variables:\n",
    "        metadata[fixed_variable[\"name\"]] = fixed_variable[\"value\"]\n",
    "        metadata_columns.append(fixed_variable[\"name\"])\n",
    "                \n",
    "    df_metadata = pd.DataFrame(metadata, columns = metadata_columns)\n",
    "    df_metadata.to_csv(filename+'-metadata.csv',encoding = 'utf-8', index=False)\n",
    "    \n",
    "    display(df_metadata)\n",
    "    display(df_result)\n",
    "\n",
    "\n",
    "\n",
    "def experiment_percentage_of_train_cases(PERCENTAGE_OF_TRAIN_CASES_RANGE, \n",
    "                                     N_NEIGHBORS, N_COMPONENTS, \n",
    "                                     N_ITERATIONS, EPSILON):\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%m-%d-%H-%M-%S\")\n",
    "    \n",
    "    experiment_results = []\n",
    "    \n",
    "    for PERCENTAGE_OF_TRAIN_CASES in PERCENTAGE_OF_TRAIN_CASES_RANGE:\n",
    "        \n",
    "        (acc, precision, recall, \n",
    "         f1, kappa, execution_time) =  pca_experiment(PERCENTAGE_OF_TRAIN_CASES, \n",
    "                                                      N_NEIGHBORS, N_COMPONENTS, \n",
    "                                                      N_ITERATIONS, EPSILON)\n",
    "        \n",
    "        data ={\n",
    "            'PERCENTAGE_OF_TRAIN_CASES' : PERCENTAGE_OF_TRAIN_CASES,\n",
    "            'ACCURACY' : acc,\n",
    "            'TIME' : round(execution_time) \n",
    "        }\n",
    "        \n",
    "        for i in range(10):\n",
    "            data['PRECISION_'+str(i)] = precision[i]\n",
    "            data['RECALL_'+str(i)] = recall[i]\n",
    "            data['F1_'+str(i)] = f1[i]\n",
    "            \n",
    "        experiment_results.append(data)\n",
    "    \n",
    "    filename='{}\\test_PERCENTAGE_OF_TRAIN_CASES-{}'.format(time.time())\n",
    "    \n",
    "    df_result = create_df('PERCENTAGE_OF_TRAIN_CASES', experiment_results)  \n",
    "    df_result.to_csv(filename+'.csv', encoding='utf-8', index=False)\n",
    "    \n",
    "    metadata = {\n",
    "        'N_NEIGHBORS': [N_NEIGHBORS],\n",
    "        'N_COMPONENTS': [N_COMPONENTS],\n",
    "        'N_ITERATIONS': [N_ITERATIONS],\n",
    "        'EPSILON': [EPSILON],\n",
    "        'TIMESTAMP' : [timestamp]\n",
    "    } \n",
    "    df_metadata = pd.DataFrame(metadata, \n",
    "                               columns = ['N_NEIGHBORS', 'N_COMPONENTS',\n",
    "                                          'N_ITERATIONS', 'EPSILON', 'TIMESTAMP'])\n",
    "    df_metadata.to_csv(filename+'-metadata.csv',encoding = 'utf-8', index=False)\n",
    "    \n",
    "    display(df_metadata)\n",
    "    display(df_result)\n",
    "\n",
    "        \n",
    "def main():\n",
    "    #percentage over total of train cases\n",
    "    PERCENTAGE_OF_TRAIN_CASES = 0.5\n",
    "    #neighbors for finding the mode in KNN\n",
    "    N_NEIGHBORS = 100\n",
    "    #components for PCA\n",
    "    N_COMPONENTS=40\n",
    "    #number of iterations to find eigenvalues and eigenvectors in power iteration\n",
    "    N_ITERATIONS=5000\n",
    "    #epsilon for power iteration\n",
    "    EPSILON=1e-10\n",
    "    \n",
    "    ##experiment_percentage_of_train_cases(np.linspace(0.1,1,2), N_NEIGHBORS, \n",
    "    ##                                 N_COMPONENTS, N_ITERATIONS, EPSILON)\n",
    "    \n",
    "    ##experiment_generic_move_variable({\"range\" : np.linspace(0.1,1,2), \n",
    "    ##                                  \"name\" : \"PERCENTAGE_OF_TRAIN_CASES\"},\n",
    "    ##                                [{\"name\":\"N_NEIGHBORS\",\"value\":N_NEIGHBORS},\n",
    "    ##                                 {\"name\":\"N_COMPONENTS\",\"value\":N_COMPONENTS},\n",
    "    ##                                 {\"name\":\"N_ITERATIONS\",\"value\":N_ITERATIONS},\n",
    "    ##                                 {\"name\":\"EPSILON\",\"value\":EPSILON}])\n",
    "    \n",
    "    experiment_generic_move_variable({\"range\" : np.arange(5,7,1), \n",
    "                                      \"name\" : \"N_COMPONENTS\"},\n",
    "                                    [{\"name\":\"N_NEIGHBORS\",\"value\":N_NEIGHBORS},\n",
    "                                     {\"name\":\"PERCENTAGE_OF_TRAIN_CASES\",\"value\":PERCENTAGE_OF_TRAIN_CASES},\n",
    "                                     {\"name\":\"N_ITERATIONS\",\"value\":N_ITERATIONS},\n",
    "                                     {\"name\":\"EPSILON\",\"value\":EPSILON}])\n",
    "    \n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
